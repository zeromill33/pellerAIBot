# Story 5.1: LLM 输入组装

## Status
Done

## Story
**作为** 系统（Report Generator/LLMProvider），  
**我希望** 将 MarketContext、Evidence、ClobSnapshot 等输入按约定结构组装为 LLM 可消费的输入，  
**以便** LLM 能稳定生成 Report v1 JSON 并通过后续校验。

Epic Context: 对应 Epic 5「Report v1 生成」的 E5-S1。  
[Source: prd/epic-plan.md#Epic 5：Report v1 生成]

Dependencies: 依赖 Epic 2 的市场数据采集与 Liquidity Proxy（E2-S1~E2-S4）、Epic 3 的 Tavily 检索 raw_content（E3-S2）、Epic 4 的 EvidenceBuilder 输出。  
[Source: prd/epic-plan.md#Epic 2：市场数据采集与流动性代理]  
[Source: prd/epic-plan.md#Epic 3：Tavily 多车道检索]  
[Source: prd/epic-plan.md#Epic 4：Evidence Builder]

## Acceptance Criteria
1. 在 `report.generate` step 中构造 LLM 输入对象，包含 `market_context`、`clob_snapshot`、`tavily_results`（或 EvidenceDigest 的等价字段映射），与 Prompt 约定字段一致，确保后续可直接生成 Report v1 JSON。  
   [Source: prd/appendices/prompts.md#G1. Report v1 生成 Prompt]  
   [Source: architecture/architecture-core.md#4.1 主流程（单事件）]
2. `market_context` 必须包含 `title`、`url`、`resolution_rules_raw`、`end_time`、`market_odds_yes/no`、`liquidity_proxy` 与 `price_context`（含 `signals.change_1h/change_4h/change_24h` 等），字段来源于内部 DTO；`resolution_rules_raw` 必须原样保留。  
   [Source: prd/appendices/prompts.md#G1. Report v1 生成 Prompt]  
   [Source: architecture/architecture-core.md#3.2 核心数据结构（内部标准化 DTO）]
3. `clob_snapshot` 必须包含 `book_top_levels`、`spread`、`midpoint`、`notable_walls`、`price_change_24h`（若可得），结构与 Prompt 约定对齐。  
   [Source: prd/appendices/prompts.md#G1. Report v1 生成 Prompt]  
   [Source: architecture/architecture-core.md#3.2 核心数据结构（内部标准化 DTO）]
4. `tavily_results`/证据输入需保留 `lane`、`query`、`results[{title,url,domain,published_at,raw_content}]`（或在 EvidenceDigest 中等价保留 URL/来源/时间），满足可追溯证据输入要求。  
   [Source: prd/appendices/prompts.md#G1. Report v1 生成 Prompt]  
   [Source: architecture/architecture-core.md#3.2 核心数据结构（内部标准化 DTO）]  
   [Source: architecture/coding-standards.md#5.2 证据（Evidence）必须带来源与归因]
5. 调用 LLM 时使用 `LLMProvider.generateReportV1()` 接口并设置 `config.aiProbabilityScale = "0-100"`，确保概率范围一致。  
   [Source: architecture/providers/llm.md#E.3 最小接口]  
   [Source: prd/appendices/prompts.md#G1. Report v1 生成 Prompt]
6. 输入组装需保证同一输入下顺序与内容稳定（确定性），满足可回放与测试可重复性要求。  
   [Source: architecture/coding-standards.md#2.3 数据项目必须具备：幂等与可回放]  
   [Source: architecture/coding-standards.md#11.8 可重复性（Determinism）要求]
7. E2E 回归默认 stop step 至少覆盖到 `report.generate`（在 Epic 5 开发期间逐步推进），并输出该 step 的摘要。  
   [Source: tests/e2e/publish-pipeline.e2e.test.ts]  
   [Source: src/orchestrator/pipeline.ts]

## Tasks / Subtasks
- [x] Task 1：定义 LLM 输入映射与字段对齐规则（AC: 1-5）  
  [Source: architecture/architecture-core.md#3.2 核心数据结构（内部标准化 DTO）]  
  [Source: architecture/providers/llm.md#E.3 最小接口]  
  [Source: architecture/coding-standards.md#5.2 证据（Evidence）必须带来源与归因]
  - [x] Subtask 1.1：从 Orchestrator ctx 提取 `MarketContext` 与 `PriceContext.signals` 并映射到 `market_context`
  - [x] Subtask 1.2：从 `ClobSnapshot` 映射 `clob_snapshot` 必需字段
  - [x] Subtask 1.3：将 Tavily 多车道结果或 EvidenceCandidate 映射为 `tavily_results`/EvidenceDigest，保留 URL/来源/时间等可追溯字段
  - [x] Subtask 1.4：确认 `generateReportV1` 输入结构与 `config.aiProbabilityScale` 设置
- [x] Task 2：在 Report 生成 step 落地输入组装（AC: 1-6）  
  [Source: architecture/source-tree.md#1) 源码目录结构（AI Signal Bot）]  
  [Source: architecture/coding-standards.md#2.2 Step 统一接口（强约束）]  
  [Source: architecture/coding-standards.md#4.2 Prompt 版本化与可审计]
  - [x] Subtask 2.1：在 `src/orchestrator/steps/report.generate.step.ts` 组装并传入 LLM 输入
  - [x] Subtask 2.2：在 `src/providers/llm/prompt.ts`/`index.ts` 中拼装 prompt 输入并加载 `prompts/report_v1_generate.prompt.txt`
  - [x] Subtask 2.3：对证据/检索结果做稳定排序或去重，保证输入确定性（建议排序：lane → published_at → domain → url）
- [x] Task 3：补充输入组装测试（AC: 1-6）  
  [Source: architecture/tech-stack.md#9) 测试策略]  
  [Source: architecture/coding-standards.md#11.3 单元测试范围（必须覆盖“各种情况”)]  
  [Source: architecture/coding-standards.md#11.6 LLM 测试策略（禁止“靠模型随机性”)]  
  [Source: architecture/coding-standards.md#11.8 可重复性（Determinism）要求]
  - [x] Subtask 3.1：单测覆盖 `market_context/clob_snapshot/tavily_results` 字段完整性与映射正确性
  - [x] Subtask 3.2：LLM 输入组装测试必须 mock LLM，避免真实调用
  - [x] Subtask 3.3：对稳定排序/确定性输出添加快照或等价断言
- [x] Task 4：E2E 回归覆盖到 `report.generate`（AC: 7）  
  [Source: tests/e2e/publish-pipeline.e2e.test.ts]
  - [x] Subtask 4.1：更新 E2E 默认 stop step 为 `report.generate`（如步骤已就绪）  
  - [x] Subtask 4.2：确保摘要输出包含 `report.generate` 的 input/output keys

## Dev Notes
### Previous Story Insights
No specific guidance found in architecture docs.  
[Source: architecture/architecture-core.md]

### Data Models
- `MarketContext`：title、url、description、resolution_rules_raw、end_time、market_odds_yes/no、liquidity_proxy、price_context。  
  [Source: architecture/architecture-core.md#3.2 核心数据结构（内部标准化 DTO）]
- `ClobSnapshot`：spread、midpoint、book_top_levels、notable_walls、price_change_24h。  
  [Source: architecture/architecture-core.md#3.2 核心数据结构（内部标准化 DTO）]
- `PriceContext`：latest_price、midpoint_price、history_24h 与 signals（change_1h/4h/24h、volatility_24h 等）。  
  [Source: architecture/architecture-core.md#3.2 核心数据结构（内部标准化 DTO）]
- `TavilyLaneResult`：lane、query、results[{title,url,domain,published_at,raw_content}]。  
  [Source: architecture/architecture-core.md#3.2 核心数据结构（内部标准化 DTO）]
- `EvidenceCandidate` 必须包含 source_type/url/domain/published_at/claim/stance/novelty/repeated/strength。  
  [Source: architecture/coding-standards.md#5.2 证据（Evidence）必须带来源与归因]
- LLMProvider 最小接口：`generateReportV1({ context, evidence, clob?, config })`。  
  [Source: architecture/providers/llm.md#E.3 最小接口]

### API Specifications
- 流水线主流程在 EvidenceBuilder 之后调用 LLM 生成 Report v1 JSON。  
  [Source: architecture/architecture-core.md#4.1 主流程（单事件）]
- LLM 只允许输出结构化 JSON（Renderer 只消费 JSON）。  
  [Source: architecture/architecture-core.md#2.1 架构原则]  
  [Source: architecture/coding-standards.md#4.1 LLM 只输出结构化 JSON（硬性）]

### Component Specifications
- Step 需遵循统一接口（id/run/requires/produces），顺序仅在 `pipeline.ts` 声明。  
  [Source: architecture/coding-standards.md#2.1 Step 文件命名与顺序编排]  
  [Source: architecture/coding-standards.md#2.2 Step 统一接口（强约束）]
- Prompt 必须文件化与版本化，记录 `prompt_name/prompt_sha256/model/temperature` 以便审计与回放。  
  [Source: architecture/coding-standards.md#4.2 Prompt 版本化与可审计]
- LLM 输出必须严格 JSON，schema 校验失败直接 block。  
  [Source: architecture/providers/llm.md#E.1 输出强约束]  
  [Source: architecture/coding-standards.md#4.1 LLM 只输出结构化 JSON（硬性）]

### File Locations
- `src/orchestrator/steps/report.generate.step.ts`：Report 生成 step。  
  [Source: architecture/source-tree.md#1) 源码目录结构（AI Signal Bot）]
- `src/orchestrator/types.ts`：MarketContext/ClobSnapshot/Report 等 DTO。  
  [Source: architecture/source-tree.md#1) 源码目录结构（AI Signal Bot）]
- `src/providers/llm/prompt.ts`、`src/providers/llm/index.ts`：LLM prompt 拼装与调用。  
  [Source: architecture/source-tree.md#1) 源码目录结构（AI Signal Bot）]
- `prompts/report_v1_generate.prompt.txt`：Report v1 prompt 文件。  
  [Source: architecture/source-tree.md#1) 源码目录结构（AI Signal Bot）]
- `schemas/report_v1.schema.json` / `src/validator/schema/report_v1.schema.json`：Report v1 schema。  
  [Source: architecture/source-tree.md#1) 源码目录结构（AI Signal Bot）]

### Testing Requirements
- 单元测试需覆盖所有分支/边界/错误路径。  
  [Source: architecture/coding-standards.md#11.3 单元测试范围（必须覆盖“各种情况”)]
- LLM 测试必须 mock，CI 禁止真实调用。  
  [Source: architecture/coding-standards.md#11.6 LLM 测试策略（禁止“靠模型随机性”)]
- 测试必须可重复（固定时间/随机、避免 sleep）。  
  [Source: architecture/coding-standards.md#11.8 可重复性（Determinism）要求]
- 测试形态参考单元/集成策略。  
  [Source: architecture/tech-stack.md#9) 测试策略]

### Technical Constraints
- Node.js 18+/20、TypeScript strict、ESM 模块制式。  
  [Source: architecture/tech-stack.md#2) 语言与运行时]

### Project Structure Notes
- `docs/architecture/unified-project-structure.md` 未找到；使用 `docs/architecture/source-tree.md` 作为目录结构依据。  
  [Source: architecture/source-tree.md#1) 源码目录结构（AI Signal Bot）]
- `docs/architecture/testing-strategy.md` 未找到；测试策略参考 `tech-stack.md` 与 `coding-standards.md`。  
  [Source: architecture/tech-stack.md#9) 测试策略]  
  [Source: architecture/coding-standards.md#11.3 单元测试范围（必须覆盖“各种情况”)]

## Change Log
| Date       | Version | Description | Author |
| ---------- | ------- | ----------- | ------ |
| 2026-01-27 | 0.1     | 创建故事草稿 | Bob    |
| 2026-01-27 | 0.2     | 澄清输入契约与确定性细节 | Bob    |
| 2026-01-27 | 0.3     | 纳入 E2E 覆盖到 report.generate | Winston |
| 2026-01-27 | 0.4     | 校验通过，状态调整为 Approved | Winston |
| 2026-01-27 | 0.5     | 完成 LLM 输入组装与测试 | James |

## Dev Agent Record
### Agent Model Used
GPT-5

### Debug Log References
- `npm test -- --run tests/orchestrator/report-generate.step.test.ts`

### Completion Notes List
- 新增 LLM 输入组装与确定性排序逻辑，支持 report.generate step 与 prompt 拼装。
- E2E 默认 stop step 覆盖到 report.generate，并注入 mock LLM 输出。

### File List
- src/orchestrator/steps/report.generate.step.ts
- src/orchestrator/pipeline.ts
- src/orchestrator/errors.ts
- src/providers/llm/index.ts
- src/providers/llm/prompt.ts
- src/providers/llm/types.ts
- tests/orchestrator/report-generate.step.test.ts
- tests/e2e/publish-pipeline.e2e.test.ts

## QA Results

### Review Date: 2026-01-27

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

实现清晰，LLM 输入组装字段对齐完整，证据排序保证确定性；错误路径明确，符合当前范围需求。

### Refactoring Performed

无

### Compliance Check

- Coding Standards: ✓
- Project Structure: ✓
- Testing Strategy: ✓
- All ACs Met: ✓

### Improvements Checklist

- [x] 验证 LLM 输入映射覆盖 market_context/clob_snapshot/tavily_results
- [x] 验证确定性排序与 E2E stop step 覆盖 report.generate
- [ ] （可选）为 OpenAI-compatible adapter 增加 mock contract 测试

### Security Review

未发现明显安全问题（API key 仅由环境变量提供）。

### Performance Considerations

无明显性能风险；新增 LLM 调用路径符合预期。

### Files Modified During Review

- docs/stories/5.1.llm-input-assembly.md（仅 QA Results 追加）
- docs/qa/gates/5.1-llm-输入组装.yml

### Gate Status

Gate: PASS → docs/qa/gates/5.1-llm-输入组装.yml  
Risk profile: 未执行  
NFR assessment: 未执行

### Recommended Status

[✓ Ready for Done]
